import streamlit as st
import io
import re
import zipfile
import math
import chardet
import os
import json
import random
import time
import streamlit.components.v1 as components
from github import Github

# NLP Imports
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet, stopwords
from nltk import pos_tag
from docx import Document

# Optional Spacy
try:
    import spacy
    _HAS_SPACY = True
except ImportError:
    _HAS_SPACY = False

# ------------------ 0. åˆå§‹åŒ– & èµ„æºåŠ è½½ ------------------
WORDLIST_DIR = "wordlists"
if not os.path.exists(WORDLIST_DIR):
    os.makedirs(WORDLIST_DIR)
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    if not os.path.exists(os.path.join(WORDLIST_DIR, "primary.txt")):
        with open(os.path.join(WORDLIST_DIR, "primary.txt"), "w", encoding="utf-8") as f:
            f.write("a\nan\nthe\nis\nare\nam\nhello\ngood\nbook\npen")

PRESET_WORDLISTS = {
    "ğŸ‘¶ å°å­¦æ ¸å¿ƒè¯": os.path.join(WORDLIST_DIR, "primary.txt"),
    "ğŸ‘¦ ä¸­è€ƒå¿…å¤‡è¯": os.path.join(WORDLIST_DIR, "zhongkao.txt"),
    "ğŸ‘¨â€ğŸ“ é«˜è€ƒ3500è¯": os.path.join(WORDLIST_DIR, "gaokao.txt"),
}

@st.cache_resource
def download_nltk_resources():
    resources = ["punkt", "averaged_perceptron_tagger", "averaged_perceptron_tagger_eng", "wordnet", "omw-1.4", "stopwords"]
    for r in resources:
        try: nltk.data.find(f'tokenizers/{r}')
        except LookupError: nltk.download(r, quiet=True)
        except ValueError: nltk.download(r, quiet=True)

@st.cache_resource
def load_spacy_model():
    if _HAS_SPACY:
        try: return spacy.load("en_core_web_sm", disable=["ner", "parser"])
        except Exception: return None
    return None

download_nltk_resources()
nlp_spacy = load_spacy_model()

# ------------------ 1. é¡µé¢é…ç½® & CSS è®¾è®¡ç³»ç»Ÿ (Core UI) ------------------
st.set_page_config(
    page_title="VocabMaster", 
    page_icon="âš¡", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ³¨å…¥æ·±åº¦å®šåˆ¶çš„ CSSï¼Œå¤åˆ» HTML æ¨¡æ¿çš„ Tailwind é£æ ¼
st.markdown("""
<style>
    /* å¼•å…¥å­—ä½“ï¼šPlus Jakarta Sans & Noto Sans SC */
    @import url('https://fonts.googleapis.com/css2?family=Plus+Jakarta+Sans:wght@400;500;600;700;800&family=Noto+Sans+SC:wght@400;500;700&display=swap');

    /* ----- å…¨å±€é‡ç½® ----- */
    .stApp {
        background-color: #F8FAFC; /* Slate-50 */
        font-family: 'Plus Jakarta Sans', 'Noto Sans SC', sans-serif;
        color: #1e293b;
    }
    
    h1, h2, h3, h4, h5, h6 {
        font-family: 'Plus Jakarta Sans', sans-serif;
        font-weight: 700;
        letter-spacing: -0.02em;
        color: #0f172a;
    }

    /* ----- ä¾§è¾¹æ ç¾åŒ– ----- */
    section[data-testid="stSidebar"] {
        background-color: #ffffff;
        border-right: 1px solid #f1f5f9;
        box-shadow: 4px 0 24px rgba(0,0,0,0.02);
    }
    /* éšè—ä¾§è¾¹æ é»˜è®¤çš„é¡¶éƒ¨ padding */
    section[data-testid="stSidebar"] > div {
        padding-top: 2rem;
    }

    /* ----- å¡ç‰‡ (Cards) ----- */
    /* æˆ‘ä»¬å°†ä½¿ç”¨ st.container(border=True) ä½†é€šè¿‡ CSS è¦†ç›–å®ƒçš„æ ·å¼ */
    div[data-testid="stVerticalBlock"] > div[data-testid="stVerticalBlockBorderWrapper"] > div {
        border: 1px solid #e2e8f0; /* Slate-200 */
        border-radius: 16px;
        background-color: #ffffff;
        box-shadow: 0 4px 20px -2px rgba(0, 0, 0, 0.05); /* Soft Shadow */
        padding: 24px;
    }

    /* ----- æŒ‰é’® (Buttons) ----- */
    /* Primary Button (Teal) */
    div.stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #2DD4BF 0%, #0F766E 100%); /* Teal Gradient */
        color: white;
        border: none;
        border-radius: 12px;
        padding: 0.6rem 1.5rem;
        font-weight: 700;
        font-size: 0.95rem;
        box-shadow: 0 4px 12px rgba(15, 118, 110, 0.2);
        transition: all 0.3s ease;
    }
    div.stButton > button[kind="primary"]:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 20px rgba(15, 118, 110, 0.3);
    }
    
    /* Secondary Button */
    div.stButton > button[kind="secondary"] {
        background-color: #F0FDFA; /* Teal-50 */
        color: #0F766E; /* Teal-700 */
        border: 1px solid #CCFBF1;
        border-radius: 10px;
        font-weight: 600;
    }

    /* ----- è¾“å…¥ç»„ä»¶ ----- */
    /* Selectbox, TextInput, NumberInput */
    .stSelectbox > div > div, .stTextInput > div > div, .stNumberInput > div > div {
        background-color: #F8FAFC;
        border: 1px solid #cbd5e1;
        border-radius: 10px;
        color: #334155;
    }
    .stSelectbox > div > div:focus-within {
        border-color: #2DD4BF;
        box-shadow: 0 0 0 3px rgba(45, 212, 191, 0.1);
    }
    
    /* File Uploader - Dotted Style */
    [data-testid="stFileUploader"] {
        background-color: #F8FAFC;
        border: 2px dashed #cbd5e1;
        border-radius: 16px;
        padding: 20px;
        text-align: center;
        transition: border-color 0.3s;
    }
    [data-testid="stFileUploader"]:hover {
        border-color: #2DD4BF;
        background-color: #F0FDFA;
    }

    /* ----- 3D ä¹¦ç±ç‰¹æ•ˆ (ç§»æ¤è‡ª HTML) ----- */
    .book-container {
        perspective: 1000px;
        margin-bottom: 20px;
    }
    .book-3d {
        width: 100%;
        aspect-ratio: 3/4;
        border-radius: 4px 12px 12px 4px;
        position: relative;
        transform-style: preserve-3d;
        transition: transform 0.3s ease;
        box-shadow: 5px 5px 15px rgba(0,0,0,0.1);
        cursor: pointer;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        text-align: center;
        padding: 15px;
        overflow: hidden;
    }
    .book-3d:hover {
        transform: translateY(-8px) rotateY(-5deg) scale(1.02);
        box-shadow: 10px 15px 25px rgba(0,0,0,0.15);
    }
    /* ä¹¦è„Šæ•ˆæœ */
    .book-spine {
        position: absolute;
        left: 0;
        top: 0;
        bottom: 0;
        width: 12px;
        background: linear-gradient(90deg, rgba(255,255,255,0.2) 0%, rgba(255,255,255,0) 100%);
        z-index: 10;
        border-right: 1px solid rgba(0,0,0,0.05);
    }
    .book-badge {
        position: absolute;
        top: 12px;
        left: 16px;
        background: rgba(255,255,255,0.9);
        backdrop-filter: blur(4px);
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 10px;
        font-weight: 800;
        color: #1e293b;
        z-index: 20;
    }

    /* éšè— Streamlit è‡ªå¸¦çš„ Header è£…é¥°æ¡ */
    header[data-testid="stHeader"] {
        background: transparent;
    }
    .stMain {
        margin-top: -60px; /* æ‹‰èµ·å†…å®¹åŒº */
    }

</style>
""", unsafe_allow_html=True)

# ------------------ 2. åŠŸèƒ½é€»è¾‘ (Backend) ------------------
def extract_text_from_bytes(file_obj, filename):
    if '.' in filename: ext = filename.split('.')[-1].lower()
    else: ext = 'txt'
    text = ""
    try:
        if ext == 'docx':
            doc = Document(file_obj)
            text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
        else:
            raw = file_obj.read()
            enc = chardet.detect(raw).get('encoding') or 'utf-8'
            text = raw.decode(enc, errors='ignore')
    except: return ""
    
    if ext in ['srt', 'vtt', 'ass']:
        text = re.sub(r"<.*?>", "", text)
        text = re.sub(r"\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}", "", text)
    return text

def process_words(all_text, mode, min_len, filter_set=None):
    TOKEN_RE = re.compile(r"[A-Za-z-]+")
    cleaned = [re.sub(r'[^a-z]', '', w.lower()) for w in TOKEN_RE.findall(all_text) if w]
    lemmatized = []
    
    if mode == "spacy" and nlp_spacy:
        # åˆ†å—å¤„ç†é˜²æ­¢å†…å­˜æº¢å‡º
        chunks = [cleaned[i:i + 50000] for i in range(0, len(cleaned), 50000)]
        for chunk in chunks:
            doc = nlp_spacy(" ".join(chunk))
            for token in doc:
                lw = token.lemma_.lower()
                if lw.isalpha() and wordnet.synsets(lw): lemmatized.append(lw)
    else:
        lemmatizer = WordNetLemmatizer()
        for w, tag in pos_tag(cleaned):
            wn = {'J':wordnet.ADJ,'V':wordnet.VERB,'N':wordnet.NOUN,'R':wordnet.ADV}.get(tag[0], None)
            lw = lemmatizer.lemmatize(w, wn) if wn else lemmatizer.lemmatize(w)
            if wordnet.synsets(lw): lemmatized.append(lw)

    seen = set()
    final_words = []
    sys_stopwords = set(stopwords.words('english'))
    for w in lemmatized:
        if len(w) < min_len: continue
        if w in sys_stopwords: continue
        if filter_set and w in filter_set: continue
        if w not in seen:
            seen.add(w)
            final_words.append(w)
    return final_words

# ------------------ 3. è‡ªå®šä¹‰ç»„ä»¶ (Copy Button) ------------------
def render_copy_button(text_content):
    safe_text = json.dumps(text_content)
    # åŒ¹é… Teal ä¸»é¢˜çš„å¤åˆ¶æŒ‰é’®
    html_code = f"""
    <script>
    function copyText() {{
        const text = {safe_text};
        const el = document.createElement('textarea');
        el.value = text;
        document.body.appendChild(el);
        el.select();
        document.execCommand('copy');
        document.body.removeChild(el);
        const btn = document.getElementById("copy_btn");
        btn.innerHTML = "âœ… å·²å¤åˆ¶ (Copied!)";
        btn.style.background = "#059669";
        setTimeout(() => {{ 
            btn.innerHTML = "ğŸ“‹ ä¸€é”®å¤åˆ¶ç»“æœ (Copy)"; 
            btn.style.background = "linear-gradient(135deg, #2DD4BF 0%, #0F766E 100%)";
        }}, 2000);
    }}
    </script>
    <button id="copy_btn" onclick="copyText()" style="
        width: 100%; padding: 12px; 
        background: linear-gradient(135deg, #2DD4BF 0%, #0F766E 100%); 
        color: white; border: none; border-radius: 12px; 
        font-family: sans-serif; font-weight: 700; cursor: pointer;
        box-shadow: 0 4px 12px rgba(15, 118, 110, 0.2); transition: all 0.3s;">
        ğŸ“‹ ä¸€é”®å¤åˆ¶ç»“æœ (Copy)
    </button>
    """
    components.html(html_code, height=60)

# ------------------ 4. ä¸»ç•Œé¢å¸ƒå±€ ------------------

# ä¾§è¾¹æ 
with st.sidebar:
    # Logo åŒºåŸŸ
    st.markdown("""
        <div style="display:flex; align-items:center; gap:10px; margin-bottom:20px;">
            <div style="width:36px; height:36px; background:linear-gradient(135deg, #2DD4BF, #0F766E); border-radius:8px; display:flex; align-items:center; justify-content:center; color:white; font-weight:bold; box-shadow:0 0 15px rgba(45,212,191,0.4);">V</div>
            <h2 style="margin:0; font-size:1.2rem; color:#0f172a;">VocabMaster</h2>
        </div>
    """, unsafe_allow_html=True)
    
    menu = st.radio("MENU", ["âš¡ æ™ºèƒ½å·¥ä½œå°", "ğŸ“š å…¬å…±è¯ä¹¦åº“", "ğŸ‘¤ ä¸ªäººä¸­å¿ƒ"], label_visibility="collapsed")
    
    st.markdown("---")
    st.markdown("<div style='background:#f0fdfa; padding:12px; border-radius:8px; color:#0f766e; font-size:0.85rem;'><b>ğŸ’¡ Pro Tips:</b><br>ä½¿ç”¨ Spacy å¼•æ“å¯è·å¾—æ›´ç²¾å‡†çš„è¯å½¢è¿˜åŸ (Better Lemmatization).</div>", unsafe_allow_html=True)

# é¡¶éƒ¨å¯¼èˆªæ  (æ¨¡æ‹Ÿ)
c_title, c_user = st.columns([3, 1])
with c_title:
    if "å·¥ä½œå°" in menu:
        st.title("æ™ºèƒ½ç”Ÿè¯æå–")
        st.caption("AI èµ‹èƒ½ï¼Œä¸€é”®ç”Ÿæˆä¸“å±è¯ä¹¦ (Workbench)")
    elif "è¯ä¹¦åº“" in menu:
        st.title("å…¬å…±è¯ä¹¦åº“")
        st.caption("å‘ç°ä¼˜è´¨è¯­æ–™ï¼Œå¼€å¯å­¦ä¹ ä¹‹æ—… (Library)")
    else:
        st.title("ä¸ªäººä¸­å¿ƒ")

with c_user:
    # æ¨¡æ‹Ÿç”¨æˆ·å¤´åƒ
    st.markdown("""
    <div style="display:flex; justify-content:flex-end; align-items:center; gap:10px; padding-top:10px;">
        <span style="background:white; padding:4px 10px; border-radius:20px; border:1px solid #e2e8f0; font-size:12px; font-weight:bold; color:#475569;">ğŸš€ Free Plan</span>
        <img src="https://api.dicebear.com/7.x/notionists/svg?seed=Felix" style="width:40px; height:40px; border-radius:50%; border:2px solid white; box-shadow:0 2px 5px rgba(0,0,0,0.1);">
    </div>
    """, unsafe_allow_html=True)

st.markdown("<br>", unsafe_allow_html=True)

# === âš¡ æ™ºèƒ½å·¥ä½œå° ===
if "å·¥ä½œå°" in menu:
    if 'result_words' not in st.session_state: st.session_state.result_words = []
    
    # é‡‡ç”¨ 1:2.5 çš„å¸ƒå±€å¤åˆ» HTML
    col_config, col_main = st.columns([1, 2.5], gap="medium")
    
    # å·¦ä¾§ï¼šé…ç½®å¡ç‰‡
    with col_config:
        with st.container(border=True): # å®é™…ä¸Šè¢« CSS æ ·å¼åŒ–ä¸ºç™½è‰²å¡ç‰‡
            st.markdown("##### ğŸ› ï¸ æå–é…ç½®")
            
            st.caption("AI å¼•æ“ (ENGINE)")
            nlp_mode = st.selectbox("Engine", ["nltk (å¿«é€Ÿ)", "spacy (ç²¾å‡†)"], label_visibility="collapsed")
            
            st.markdown("<br>", unsafe_allow_html=True)
            st.caption("æ’åºæ–¹å¼ (SORT)")
            sort_order = st.selectbox("Sort", ["æŒ‰æ–‡æœ¬å‡ºç°é¡ºåº", "æŒ‰å­—æ¯ A-Z", "éšæœºæ‰“ä¹±"], label_visibility="collapsed")
            
            st.markdown("<br>", unsafe_allow_html=True)
            st.caption(f"æœ€çŸ­è¯é•¿ (MIN LENGTH)")
            min_len = st.slider("Min Len", 2, 15, 3, label_visibility="collapsed")
            
            st.markdown("---")
            st.markdown("##### ğŸ›¡ï¸ ç†Ÿè¯å±è”½")
            # é¢„ç½®è¯åº“
            selected_presets = st.multiselect(
                "é€‰æ‹©é¢„ç½®åº“",
                options=list(PRESET_WORDLISTS.keys()),
                default=[],
                label_visibility="collapsed",
                placeholder="é€‰æ‹©è¦å±è”½çš„è¯æ±‡ç­‰çº§..."
            )
            # è‡ªå®šä¹‰ä¸Šä¼ 
            st.markdown("<div style='height:8px'></div>", unsafe_allow_html=True)
            filter_file = st.file_uploader("ä¸Šä¼ è‡ªå®šä¹‰å±è”½è¡¨ (.txt)", type=['txt'], label_visibility="collapsed")
            if filter_file: st.caption(f"å·²åŠ è½½: {filter_file.name}")

            # å¤„ç† Filter
            filter_set = set()
            for p in selected_presets:
                path = PRESET_WORDLISTS[p]
                if os.path.exists(path):
                    with open(path,'r',encoding='utf-8') as f: filter_set.update(f.read().splitlines())
            if filter_file:
                filter_set.update(filter_file.getvalue().decode('utf-8', errors='ignore').splitlines())

    # å³ä¾§ï¼šä¸»æ“ä½œåŒº
    with col_main:
        with st.container(border=True):
            st.markdown("""
            <div style="display:flex; justify-content:space-between; margin-bottom:10px;">
                <span style="font-size:12px; font-weight:bold; color:#94a3b8; letter-spacing:1px;">INPUT SOURCE</span>
            </div>
            """, unsafe_allow_html=True)
            
            input_text = st.text_area("Input", height=200, placeholder="åœ¨æ­¤ç²˜è´´æ–‡ç« ã€å­—å¹•æ–‡æœ¬ã€æ­Œè¯...\næˆ–è€…ç‚¹å‡»ä¸‹æ–¹è™šçº¿æ¡†ä¸Šä¼ æ–‡ä»¶", label_visibility="collapsed")
            
            uploaded_files = st.file_uploader("æˆ–æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„ (æ”¯æŒ .srt, .docx, .txt)", type=['txt','srt','ass','docx'], accept_multiple_files=True, label_visibility="collapsed")

            col_act_1, col_act_2 = st.columns([3, 1])
            with col_act_2:
                st.markdown("<br>", unsafe_allow_html=True)
                start_btn = st.button("ğŸš€ å¼€å§‹æ™ºèƒ½æå–", type="primary", use_container_width=True)

        # å¤„ç†é€»è¾‘
        if start_btn:
            full_text = input_text
            if uploaded_files:
                for f in uploaded_files:
                    full_text += "\n" + extract_text_from_bytes(f, f.name)
            
            if not full_text.strip():
                st.warning("âš ï¸ è¯·å…ˆè¾“å…¥æ–‡æœ¬æˆ–ä¸Šä¼ æ–‡ä»¶")
            else:
                with st.spinner("AI æ­£åœ¨åˆ†æè¯­ä¹‰ä¸è¯å½¢..."):
                    mode_key = "spacy" if "spacy" in nlp_mode else "nltk"
                    words = process_words(full_text, mode_key, min_len, filter_set)
                    
                    if sort_order == "æŒ‰å­—æ¯ A-Z": words.sort()
                    elif sort_order == "éšæœºæ‰“ä¹±": random.shuffle(words)
                    
                    st.session_state.result_words = words
                    # å¼ºåˆ¶åˆ·æ–°ä»¥æ˜¾ç¤ºç»“æœ
                    st.rerun()

    # ç»“æœå±•ç¤º (å¦‚æœæœ‰)
    if st.session_state.result_words:
        st.markdown("<br>", unsafe_allow_html=True)
        with st.container(border=True):
            words = st.session_state.result_words
            st.markdown(f"""
            <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:15px;">
                <h3 style="margin:0;">ğŸ‰ æå–ç»“æœ</h3>
                <span style="background:#dcfce7; color:#166534; padding:2px 10px; border-radius:12px; font-size:12px; font-weight:bold;">å…± {len(words)} è¯</span>
            </div>
            """, unsafe_allow_html=True)
            
            content_str = "\n".join(words)
            # ä½¿ç”¨ text_area å±•ç¤ºç»“æœï¼Œæ–¹ä¾¿æŸ¥çœ‹
            st.text_area("Result", value=content_str, height=150, label_visibility="collapsed")
            
            c_copy, c_dl = st.columns([1, 1])
            with c_copy:
                render_copy_button(content_str)
            with c_dl:
                 st.download_button("ğŸ“¦ ä¸‹è½½ç»“æœ (.txt)", content_str, "vocab.txt", "text/plain", use_container_width=True)

# === ğŸ“š å…¬å…±è¯ä¹¦åº“ ===
elif "è¯ä¹¦åº“" in menu:
    
    # æœç´¢æ¡
    search_col, _ = st.columns([1, 2])
    with search_col:
        st.text_input("Search", placeholder="ğŸ” æœç´¢è¯ä¹¦...", label_visibility="collapsed")

    # æ¨¡æ‹Ÿæ•°æ®
    books = [
        {"title": "è€ƒç ”å¤§çº²", "sub": "2026ç‰ˆ", "color": "#FDE68A", "text": "#451a03", "badge": "HOT", "count": 5500},
        {"title": "CET-4", "sub": "é«˜é¢‘æ ¸å¿ƒ", "color": "#A7F3D0", "text": "#064e3b", "badge": "æ ¸å¿ƒ", "count": 2400},
        {"title": "æ‰˜ç¦è¯æ±‡", "sub": "ç»¿å®ä¹¦", "color": "#BFDBFE", "text": "#1e3a8a", "badge": "ç•™å­¦", "count": 3800},
        {"title": "ç»æµå­¦äºº", "sub": "ç²¾é€‰è¯æ±‡", "color": "#FECACA", "text": "#7f1d1d", "badge": "é«˜é˜¶", "count": 1200},
        {"title": "è€å‹è®°", "sub": "S01-S10", "color": "#DDD6FE", "text": "#4c1d95", "badge": "è¶£å‘³", "count": 4500},
    ]

    st.markdown("<br>", unsafe_allow_html=True)
    
    # Grid å¸ƒå±€å±•ç¤ºä¹¦ç±
    cols = st.columns(5) # 5åˆ—å¸ƒå±€
    
    for i, book in enumerate(books):
        with cols[i % 5]:
            # ä½¿ç”¨ HTML æ³¨å…¥ç”Ÿæˆ 3D ä¹¦ç±
            st.markdown(f"""
            <div class="book-container">
                <div class="book-3d" style="background-color: {book['color']}; color: {book['text']};">
                    <div class="book-spine"></div>
                    <div class="book-badge">{book['badge']}</div>
                    <h3 style="font-size:1.1rem; margin-top:20px; line-height:1.2; color:{book['text']}">{book['title']}</h3>
                    <p style="font-size:0.8rem; opacity:0.8; margin-top:5px; color:{book['text']}">{book['sub']}</p>
                    <div style="margin-top:auto; font-size:0.75rem; font-weight:bold; opacity:0.6;">{book['count']} è¯</div>
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            # ç®€å•çš„ä¸‹è½½æŒ‰é’®æ¨¡æ‹Ÿ
            st.button(f"ä¸‹è½½", key=f"dl_{i}", use_container_width=True)

# === ä¸ªäººä¸­å¿ƒ ===
else:
    st.info("ğŸš§ ä¸ªäººä¸­å¿ƒæ­£åœ¨æ–½å·¥ä¸­... (Coming Soon)")
